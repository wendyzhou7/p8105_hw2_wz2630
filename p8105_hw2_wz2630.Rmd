---
title: "p8105_hw2_wz2630"
output: github_document
date: "2023-09-28"
---
Load necessary libraries
```{r, message=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

pols
```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = 
  read_csv("./hw2_datasets/pols-month.csv") |> 
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |> 
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
  
```

snp
```{r}
snp_df = 
  read_csv("./hw2_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close)
```

unemployment
```{r}
unemployment_df = 
  read_csv("./hw2_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Merging the 3 datasets
```{r}
data_538 = 
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)

str(data_538)
```

The pols data has **822** observations and 13 variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years 1947 to 2015. It also tells us whether the sitting president was a democrat or republican. 

The snp data has **787** observations and 3 variables, ranging from years 0 to 99. 
The unemployment data has **816** observations and 3 variables ranging from years 1948 to 2015. 


# Problem 2

Mr. Trash Wheel
```{r}
mr_trash_wheel = 
  readxl::read_excel("./hw2_datasets/202309 Trash Wheel Collection Data.xlsx", 
                     range = "A2:N586") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons*500)/30, 
         name = "mr",
         year = as.numeric(year)) |> 
  select(name, everything())
```

Professor Trash Wheel
```{r}
prof_trash_wheel = 
  readxl::read_excel("./hw2_datasets/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = 2, 
                     range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons*500)/30, 
         name = "professor") |> 
  select(name, everything())
```

Gwynnda Trash Wheel
```{r}
gwynnda_trash_wheel = 
  readxl::read_excel("./hw2_datasets/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = 4, 
                     range = "A2:L157") |> 
  janitor::clean_names() |> 
  mutate(homes_powered = (weight_tons*500)/30, 
         name = "gwynnda") |> 
  select(name, everything())
```

Combining 3 trashwheel datasets
```{r}
trash_wheels_df =
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)

# total weight of trash collected by Professor Trash Wheel
sum(prof_trash_wheel[, 'weight_tons'])

# total number of cigarette butts collected by Gwynnda in July of 2021
gwynnda_trash_wheel |> 
    group_by(year, month) |>  
    summarize(num = n(),cig_butts_total = sum(cigarette_butts))
```

The combined dataset results in 845 observations and 15 variables. The key variables in this combined dataset are
name (of trash wheel), id (of trash wheel), month and year (trash was collected), weight_tons, homes_powered, and variable names indicating trash types.

The total weight of trash collected by Professor Trash Wheel is 216.26 tons.
The total number of cigarette butts collected by Gwynnda in July of 2021 is 16,300.



# Problem 3

Baseline Demographics Data
```{r}
# Load, clean, and filter baseline demographics data
mci_baseline = 
  read_csv("./hw2_datasets/data_mci/MCI_baseline.csv",
           skip = 1,
           na = c(".")) |> 
  janitor::clean_names() |> 
  rename("study_id" = "id") |> 
  mutate(
    sex = case_match(
      sex, 
      1 ~ "male",
      0 ~ "female"),
    apoe4 = case_match(
      apoe4, 
      1 ~ "carrier", 
      0 ~ "non-carrier"))
```
There are 483 observations before removing participants who did not fulfill "no MCI at baseline" criteria.

```{r}
# exclude if MCI at baseline
mci_free_baseline = 
  mci_baseline |> 
  filter(age_at_onset - current_age > 0 | is.na(age_at_onset)) 

# number of people who develop mci
develop_mci = 
  mci_baseline |> 
  filter(age_at_onset - current_age > 0)

# average baseline age
mci_free_baseline |> 
    summarize(num = n(),
              mean = mean(current_age))

# proportion of women in the study are APOE4 carriers
nrow(filter(mci_free_baseline, sex == "female" & apoe4 == "carrier")) / nrow(filter(mci_free_baseline, sex == "female"))
```
There were originally **483** participants recruited and we then removed those who did not meet the inclusion criteria of no MCI at baseline (resulting in 479 observations) and filtering for those who do develop MCI, we get **93** remaining participants (who develop MCI).

The average baseline age is **65** years old -- calculated after cleaning and removing those who did not meet no MCI
at baseline criteria.

**30%** of women in the study are APOE4 carriers.


Amyloid Data
```{r}
# Load amyloid data
  # first create a vector of participants who did not satisfy baseline criteria
excluded_id = mci_baseline |> 
  filter(age_at_onset - current_age <= 0) |> 
  pull(study_id)

  # second, clean amyloid data and filter out the participants using the vector
mci_amyloid = 
  read_csv("./hw2_datasets/data_mci/mci_amyloid.csv",
           skip = 1) |> 
  janitor::clean_names() |> 
  filter(!study_id %in% c(excluded_id))
```

**Important steps to import process:**
The important steps to importing the datasets include using the read_csv function, cleaning the variable names into snake case, using the case_match function to turn numeric values of sex and apoe4 into descriptive characters, and removing participants who do not fulfill baseline requirements.

For the amyloid dataset, it is important to first create a vector of pariticipants who did not meet baseline criteria so that filtering can happen in the same step as cleaning.

**Relevant features of dataset:**
Baseline demographics (mci_free_baseline) dataset consists of 479 observations who meet baseline criteria and 6 variables -- including study_id, current_age, sex, education (years), apeo4 (status), and age_at_onset.

Amyloid dataset consists of 483 participants after cleaning and filtering out patients who did not statisfy no MCI at baseline criteria. The dataset consists of 6 variables including study_id and amyloid β42/40 ratios recorded at baseline, and 4 other times (2, 4, 6, 8 years) sequentially after baseline. 


```{r}
# shows observations that are only in mci_baseline dataset
anti_join(mci_free_baseline, mci_amyloid, by="study_id")
```
There are 8 participants that are only included in baseline, but excluded in the amyloid dataset. The study_id of
these participants include: 14, 49, 92, 179, 268, 304, 389, 412.


```{r}
# shows observations that are only in mci_amyloid dataset
anti_join(mci_amyloid, mci_free_baseline, by="study_id")
```
There are 12 participants that are only included in amyloid, but excluded in the baseline dataset.The study_id of
these participants include: 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495.


Combining mci_free_baseline & mci_amyloid datasets with common participants
```{r}
# shows observations that are only in mci_amyloid dataset
mci = 
  inner_join(mci_baseline, mci_amyloid, by = "study_id")
```
**Resulting dataset:**
After combining the baseline demographic and biomarker datasets so that only participants who appear in both datasets are retained, the resulting dataset (baseline_amyloid) consists of **471** observations with 11 variables. These variables include study_id, current_age, sex, education, apoe4 (status), age_at_onset, baseline:time_8 (time at which amyloid β42/40 ratios were recorded).


```{r}
# Export the result as a CSV to your data directory
write_csv(mci, "./mci.csv")
```








